Reinforcement Learning is a branch of Machine Learning, also called Online Learning. It is used to solve 
interacting problems where the data observed up to time t is considered to decide which action to take at time t + 1.
 
It is also used for Artificial Intelligence when training machines to perform tasks such as walking. Desired outcomes
provide the AI with reward, undesired with punishment. Machines learn through trial and error.
In this part, you will understand and learn how to implement the following Reinforcement Learning models:

1. Upper Confidence Bound (UCB)
2. Thompson Sampling

Notes:

1.In a real life application we would want to apply this model in-situ in order to get the most out of it. imagine if we
had to pay for every ad in every round that we applied. If we kept all the ads after 10,000 rounds that would cost us a 
lot of money. So how would you invest your money? Pay for two ads for 10,000 rounds and potentially miss out on a appealing
ad? Pay for 5 ads for 5,000 rounds? Pay for 10 adds for only 100 rounds? If you chose the last option, at round 100 in our
example ad 2,5, and 8 have almost the same sum of clicks and if we pick ad 8 or 2 we have potentially wasted our money.

The purpose of the UBC and Thompson sampling models are to explore the potential for investment options and find the 
optimal option as fast as possible in order to save time and or money. This example is one of the simplest examples or
 how we can execute a UCB model.

2.numbers_of_selections = [1] * d
sums_of_rewards = [1] * d
 
ads_selected = []
for n in range(0,N):
    average_reward = np.divide(numbers_of_selections,sums_of_rewards)
    nominator = [math.sqrt( (3/2) * math.log(n+1) )] * d
    delta = np.divide(nominator, numbers_of_selections)
    upper_bound = average_reward + delta
    
    ad_to_show = np.argmax(upper_bound)
    ads_selected.append(ad_to_show)
    numbers_of_selections[ad_to_show] = numbers_of_selections[ad_to_show] + dataset.values[n,ad_to_show]
    sums_of_rewards[ad_to_show] = sums_of_rewards[ad_to_show] +1
 
print(sum( numbers_of_selections)-d)






